# -*- coding: utf-8 -*-
"""EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FjVrQ5a08RWBDxJk7u9FsKhxZALQgZU7
"""

import pandas as pd

# Cargar el archivo CSV
file_path = '/content/car_price_prediction.csv'
data = pd.read_csv(file_path)
data.head(5)

# Ver el número total de filas y columnas
print(data.shape)

# Ver la información general sobre el dataset (tipos de datos, valores no nulos, etc.)
data.info()

# Ver estadísticas descriptivas (solo para columnas numéricas)
print(data.describe())

# Ver el número de valores únicos en cada columna
print(data.nunique())

# Contar la cantidad de valores faltantes por columna
print(data.isnull().sum())

# 4. Revisar las columnas categóricas (no numéricas) y sus valores únicos
print("\nValores únicos en las columnas categóricas:")
for col in data.select_dtypes(include=['object']).columns:
    print(f"{col}: {data[col].unique()[:10]}")  # Muestra los primeros 10 valores únicos

# 5. Revisar si hay filas duplicadas
print("\n¿Existen filas duplicadas?:")
print(data.duplicated().sum())

# Eliminar filas duplicadas
data = data.drop_duplicates()

# 5. Revisar si hay filas duplicadas
print("\n¿Existen filas duplicadas?:")
print(data.duplicated().sum())

# Eliminar la unidad 'km' de la columna Mileage y convertir a tipo numérico
data['Mileage'] = data['Mileage'].str.replace(' km', '').replace('-', None).astype(float)

data.head()

# Convertir 'Price', 'Levy', 'Cylinders', y 'Engine volume' a valores numéricos, manejando entradas no válidas
data['Price'] = pd.to_numeric(data['Price'], errors='coerce')
data['Levy'] = pd.to_numeric(data['Levy'], errors='coerce')
data['Cylinders'] = pd.to_numeric(data['Cylinders'], errors='coerce')
data['Engine volume'] = pd.to_numeric(data['Engine volume'], errors='coerce')

# Contar la cantidad de valores faltantes por columna
print(data.isnull().sum())

"""Se ha decidido rellenar los valores nulos de la columna **Levy** con **0** porque, en muchos casos, la ausencia de este dato puede indicar que el auto no está sujeto a ese impuesto o tarifa. Esto es más representativo que eliminar los datos o utilizar una estimación arbitraria.

En cuanto a la columna **Engine volume**, se ha rellenado con la **mediana** para mantener la integridad de los datos, ya que el tamaño del motor es un atributo clave del vehículo. La mediana es menos sensible a valores extremos, lo que evita distorsiones y asegura que los valores faltantes se aproximen a la mayoría de los autos del dataset.

Este enfoque mantiene la mayor cantidad posible de información sin comprometer la calidad del análisis.
"""

# Rellenar valores nulos de 'Levy' con 0
data['Levy'].fillna(0, inplace=True)

# Rellenar valores nulos de 'Engine volume' con la mediana
data['Engine volume'].fillna(data['Engine volume'].median(), inplace=True)

# Verificar si los valores nulos han sido manejados
print(data.isnull().sum())

# Si deseas guardar el dataset limpio en un nuevo archivo CSV
output_path = '/content/car_price_prediction3.csv'
data.to_csv(output_path, index=False)

import matplotlib.pyplot as plt
import seaborn as sns

# Establecer estilo para las visualizaciones
sns.set(style="whitegrid")

# 1. Distribución de los Precios de los Autos
plt.figure(figsize=(10, 6))
sns.histplot(data['Price'], bins=50, kde=True)
plt.title('Distribución de los Precios de los Autos')
plt.xlabel('Precio')
plt.ylabel('Frecuencia')
plt.xlim(0, 100000)  # Limitando el eje x para enfocarse en la mayoría de los datos
plt.show()

# 2. Año de Producción vs. Precio (Gráfico de dispersión)
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Prod. year', y='Price', data=data)
plt.title('Precio del Auto vs. Año de Producción')
plt.xlabel('Año de Producción')
plt.ylabel('Precio')
plt.ylim(0, 1000000)  # Limitando el eje y para enfocarse en la mayoría de los datos
plt.show()

# 3. Distribución del Volumen del Motor
plt.figure(figsize=(10, 6))
sns.histplot(data['Engine volume'], bins=30, kde=True)
plt.title('Distribución del Volumen del Motor')
plt.xlabel('Volumen del Motor')
plt.ylabel('Frecuencia')
plt.show()

# 4. Precio del Auto según el Tipo de Combustible
plt.figure(figsize=(10, 6))
sns.boxplot(x='Fuel type', y='Price', data=data)
plt.title('Distribución de Precios por Tipo de Combustible')
plt.xlabel('Tipo de Combustible')
plt.ylabel('Precio')
plt.ylim(0, 100000)  # Limitando el eje y para enfocarse en la mayoría de los datos
plt.show()

# 5. Precio del Auto según el Tipo de Caja de Cambios
plt.figure(figsize=(10, 6))
sns.boxplot(x='Gear box type', y='Price', data=data)
plt.title('Distribución de Precios por Tipo de Caja de Cambios')
plt.xlabel('Tipo de Caja de Cambios')
plt.ylabel('Precio')
plt.ylim(0, 100000)  # Limitando el eje y para enfocarse en la mayoría de los datos
plt.show()

"""Principales hallazgos de las visualizaciones:

Distribución de los precios de los autos:

La mayoría de los precios de los autos están concentrados por debajo de $100,000, con una caída abrupta en la frecuencia a medida que el precio aumenta.
Hay algunos precios extremadamente altos, pero el enfoque principal está en autos asequibles.
Precio del auto vs. año de producción:

Los precios generalmente aumentan con los años de producción más recientes. Sin embargo, algunos modelos antiguos tienen precios más altos, probablemente debido a su estatus de lujo o autos clásicos.
La concentración de datos se encuentra alrededor de los años 2010-2020, lo que refleja que los autos modernos son más comunes en este conjunto de datos.
Distribución del volumen del motor:

La mayoría de los autos tienen volúmenes de motor entre 1.5 y 3 litros.
Existen algunos valores atípicos con volúmenes de motor de hasta 20 litros, lo que podría representar vehículos especializados o de lujo.
Precio del auto según el tipo de combustible:

Los autos híbridos y diésel tienden a tener una mayor variabilidad en sus precios, con los híbridos mostrando algunos de los precios más altos.
Los autos de gasolina tienen una distribución de precios más uniforme, mayormente en los rangos más bajos.
Precio del auto según el tipo de caja de cambios:

Los autos con cajas automáticas tienden a tener precios más altos en promedio, en comparación con aquellos con transmisiones manuales o de variador, lo que refleja quizá una preferencia por la comodidad en los autos modernos.
"""

plt.figure(figsize=(10, 6))
sns.scatterplot(x='Mileage', y='Price', data=data)
plt.title('Relación entre Kilometraje y Precio del Auto')
plt.xlabel('Kilometraje')
plt.ylabel('Precio')
plt.xlim(0, 500000)  # Limitar el kilometraje para evitar valores extremos
plt.ylim(0, 1000000)  # Limitar el precio
plt.show()

"""Relación entre kilometraje y precio:

No se observa una tendencia clara entre el kilometraje y el precio. Aunque existe una ligera relación negativa, hay muchos puntos dispersos. Esto sugiere que, además del kilometraje, otros factores importantes (como el tipo de vehículo, la marca, o el año de producción) también afectan el precio.
"""

# Precio promedio por fabricante
plt.figure(figsize=(12, 6))
manufacturer_price = data.groupby('Manufacturer')['Price'].mean().sort_values(ascending=False)
sns.barplot(x=manufacturer_price.index, y=manufacturer_price.values)
plt.xticks(rotation=90)
plt.title('Precio Promedio por Fabricante')
plt.xlabel('Fabricante')
plt.ylabel('Precio Promedio')
plt.show()

"""Precio promedio por fabricante:

Fabricantes como Tesla, Porsche, y Lexus tienen precios promedio significativamente más altos que marcas como Chevrolet y Ford.
Los resultados reflejan que los fabricantes de lujo tienden a mantener precios elevados, mientras que las marcas más accesibles tienen precios promedio más bajos.
"""

plt.figure(figsize=(10, 6))
sns.boxplot(x='Category', y='Price', data=data)
plt.title('Distribución de Precios por Categoría de Vehículo')
plt.xlabel('Categoría de Vehículo')
plt.ylabel('Precio')
plt.ylim(0, 100000)  # Limitar el precio para enfocarnos en datos relevantes
plt.xticks(rotation=90)
plt.show()

"""Distribución de precios por categoría de vehículo:

Las categorías de autos de lujo como los Jeep y los Minivan muestran una amplia variación en el precio, lo que sugiere que estos tipos de vehículos pueden abarcar tanto autos de gama baja como alta.
En comparación, los Hatchback y Sedán tienden a tener precios más uniformes y generalmente más bajos.
"""

# Identificación de outliers en el precio
plt.figure(figsize=(10, 6))
sns.boxplot(x='Price', data=data)
plt.title('Outliers en Precios de Autos')
plt.show()

# Identificación de outliers en el kilometraje
plt.figure(figsize=(10, 6))
sns.boxplot(x='Mileage', data=data)
plt.title('Outliers en Kilometraje de Autos')
plt.show()

"""Outliers en precios:

Hay varios valores atípicos en los precios, con algunos autos extremadamente caros. Esto puede incluir autos de lujo o vehículos personalizados que no siguen la tendencia promedio.

Outliers en kilometraje:

Existen algunos outliers extremos en el kilometraje. Algunos autos tienen kilometrajes excesivamente altos, lo que podría deberse a errores en los datos o a situaciones excepcionales (por ejemplo, autos de servicio pesado).
"""

plt.figure(figsize=(10, 6))
sns.boxplot(x='Fuel type', y='Price', data=data)
plt.title('Precio del Auto por Tipo de Combustible')
plt.xlabel('Tipo de Combustible')
plt.ylabel('Precio')
plt.ylim(0, 100000)  # Limitar el precio
plt.show()

"""Precio por tipo de combustible:
De acuerdo con el análisis:

Los autos diésel tienen el precio promedio más alto, seguidos de los híbridos enchufables y los vehículos de hidrógeno.
Los autos de gasolina tienen un precio promedio de 17,391.
Sorprendentemente, los autos híbridos no tienen un precio tan alto como se esperaba, con un precio promedio de 10,845.
"""

plt.figure(figsize=(10, 6))
sns.boxplot(x='Airbags', y='Price', data=data)
plt.title('Relación entre Cantidad de Airbags y Precio del Auto')
plt.xlabel('Número de Airbags')
plt.ylabel('Precio')
plt.ylim(0, 100000)  # Limitar el precio
plt.show()

"""Para la relación entre el número de airbags y el precio, según el gráfico de caja y bigote que generamos anteriormente, las siguientes conclusiones pueden extraerse:

1. **Mayor número de airbags, precios más altos**:
   - En general, los autos con **más airbags** tienden a tener precios más altos. Esto es coherente con la idea de que los vehículos con más características de seguridad suelen ser más costosos.
   
2. **Distribución uniforme para ciertos valores**:
   - Los autos con **6 airbags** parecen ser muy comunes, con una distribución de precios amplia, lo que sugiere que este es un número típico de airbags para vehículos de gama media.
   - Los autos con **12 o más airbags** tienden a ser más caros, lo que indica que suelen pertenecer a vehículos de lujo o de alta gama.

3. **Precios bajos con pocos airbags**:
   - Los autos con **0 o 2 airbags** tienden a tener precios más bajos, lo cual es lógico ya que estos vehículos probablemente tienen menos características de seguridad y son modelos más económicos o antiguos.

4. **Variabilidad en los precios**:
   - Aunque en general más airbags se asocian con precios más altos, también hay bastante variabilidad dentro de cada grupo. Esto sugiere que, además del número de airbags, otros factores como el fabricante, la categoría del auto o el año de producción también tienen un impacto significativo en el precio.

En resumen, los resultados sugieren que un mayor número de airbags está correlacionado con precios más altos, pero no es el único factor determinante del precio.
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar los datos
df = data

# Preprocesamiento: Codificación de variables categóricas
df_encoded = df.copy()

# Convertir las columnas categóricas en variables numéricas
label_encoders = {}
categorical_columns = df_encoded.select_dtypes(include=['object']).columns

for col in categorical_columns:
    le = LabelEncoder()
    df_encoded[col] = le.fit_transform(df_encoded[col])
    label_encoders[col] = le

# Definir las características (X) y la variable objetivo (y)
X = df_encoded.drop(columns=['Price', 'ID'])  # Excluimos 'Price' (target) y 'ID'
y = df_encoded['Price']

# Dividir los datos en conjunto de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenar los tres modelos

# 1. Regresión Lineal
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
y_pred_lr = lr_model.predict(X_test)

# 2. Árbol de Decisión
dt_model = DecisionTreeRegressor(random_state=42)
dt_model.fit(X_train, y_train)
y_pred_dt = dt_model.predict(X_test)

# 3. Random Forest
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

# Evaluar el rendimiento de los tres modelos
def evaluate_model(y_test, y_pred, model_name):
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    print(f'{model_name} - MAE: {mae:.2f}, RMSE: {rmse:.2f}, R²: {r2:.2f}')

# Comparar los modelos
evaluate_model(y_test, y_pred_lr, "Regresión Lineal")
evaluate_model(y_test, y_pred_dt, "Árbol de Decisión")
evaluate_model(y_test, y_pred_rf, "Random Forest")

import joblib

# Supongamos que 'best_model' es el modelo que quieres guardar.
joblib.dump(dt_model, '/content/modelo.pkl')

# Cargar el modelo
model = joblib.load('/content/modelo.pkl')

data5 = data.head(5)

features = data5[['Levy', 'Manufacturer', 'Model', 'Prod. year', 'Category', 'Leather interior', 'Fuel type', 'Engine volume', 'Mileage', 'Cylinders', 'Gear box type', 'Drive wheels', 'Doors', 'Wheel', 'Color', 'Airbags']]

# Convertir las columnas categóricas en variables numéricas
label_encoders = {}
categorical_columns = data5.select_dtypes(include=['object']).columns

for col in categorical_columns:
    le = LabelEncoder()
    data5[col] = le.fit_transform(data5[col])
    label_encoders[col] = le

categorical_columns

# Realizar predicciones
predictions = model.predict(data5.drop(columns=['Price', 'ID']))

predictions

# Si deseas guardar el dataset limpio en un nuevo archivo CSV
output_path = '/content/car_price_prediction5.csv'
data5.to_csv(output_path, index=False)

"""Conclusión:
El Árbol de Decisión es el modelo que mejor predice el precio de los autos, ya que tiene el menor error absoluto medio (MAE) y un
𝑅
2
R
2
  positivo, lo que indica que explica mejor la variabilidad en los precios.
Aunque el Random Forest generalmente supera a los árboles de decisión, en este caso, su configuración no fue óptima y dio un rendimiento peor.
La Regresión Lineal no es adecuada para este problema, dado que no captura bien las relaciones no lineales entre las características y el precio.

Para mejorar el rendimiento del modelo de Random Forest, ajustaremos algunos hiperparámetros clave, como el número de árboles (n_estimators), la profundidad máxima del árbol (max_depth), y el número mínimo de muestras por hoja (min_samples_leaf). Además, podemos probar otros enfoques como la validación cruzada para asegurar que el modelo no se sobreajuste.

Estrategia de ajuste de hiperparámetros:
Grid Search: Se probarán diferentes combinaciones de hiperparámetros para encontrar la mejor configuración.
Validación cruzada: Usaremos validación cruzada para obtener una mejor estimación del rendimiento general del modelo.
"""

from sklearn.model_selection import GridSearchCV

# Definir el modelo de Random Forest
rf_model = RandomForestRegressor(random_state=42)

# Definir el grid de hiperparámetros a probar
param_grid = {
    'n_estimators': [100, 200, 300],         # Número de árboles en el bosque
    'max_depth': [10, 20, 30, None],         # Profundidad máxima de los árboles
    'min_samples_split': [2, 5, 10],         # Mínimo de muestras para dividir un nodo
    'min_samples_leaf': [1, 2, 4],           # Mínimo de muestras en una hoja
    'bootstrap': [True, False]               # Si se usa muestreo con reemplazo
}

# Usar GridSearchCV para probar todas las combinaciones de hiperparámetros
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=3)
grid_search.fit(X_train, y_train)

# Mostrar los mejores hiperparámetros encontrados
print("Mejores hiperparámetros encontrados:")
print(grid_search.best_params_)

# Predecir con el mejor modelo
best_rf_model = grid_search.best_estimator_
y_pred_best_rf = best_rf_model.predict(X_test)

# Evaluar el mejor modelo
evaluate_model(y_test, y_pred_best_rf, "Mejor Random Forest")